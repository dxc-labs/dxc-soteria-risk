{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soteria - Decisions: Risk Profile Engine - Multi Classification Model\n",
    "***\n",
    "##### __Project: Soteria__\n",
    "##### __Module: Decisions: Risk Profile Engine (RPE)__\n",
    "##### __Program: Soteria-Decisions-RiskProfileEngine-Model.ipynb__\n",
    "##### __Written by: Devarayan Subbu__\n",
    "\n",
    "_Prerequisite on access to AWS environment: In order to run this python notebook, you should have necessary access privileges to your AWS environment - especially to AWS SageMaker and S3 and that you have already created and ready to go AWS SageMaker Notebook instance along with neessary IAM roles. Refer to AWS documentation for further help on AWS services (SageMaker, S3, IAM, etc) and/ or creating Notebook instances._\n",
    "***\n",
    "\n",
    "This __model is based on the XGBoost__ (eXtreme Gradient Boosting) - an implementation of the gradient boosted trees algorithm. Gradient boosting is a _supervised learning algorithm_ that attempts to accurately _predict a target variable by combining an ensemble of estimates from a set of simpler and weaker models_.\n",
    "\n",
    "Our requirement is to __predict__ the __risk category__ based on specific features. And, in our case, these features are __temperature, spo2, travel_history, positive_contact, symptoms_none, dry_cough, shortness_of_breath, chest_pain_or_pressure, confusion_or_problems_thinking, bluish_lips_or_face, sore_throat, fatigue, aches_and_pain, loss_of_appetite_or_smell, headache, stuffy_or_runny_nose, vomiting, diarrhea, sneezing, overall_health_status__. Given these input features, the model predicts the risk category (of low/ medium/ high)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install XGBoost and import necessary libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost==1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import boto3\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import plot_tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the region, client, session, role, bucket prefix and bucket to store the datasets, and evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name    \n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "session=sagemaker.Session()\n",
    "objective_metric_name = 'validation:mlogloss'\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket='soteria-decisions-risk-engine'\n",
    "prefix = 'SOTERIA-SM-XGB-HT/RPE-V0.53'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the train, validation, and test split percentages and also read the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENTAGE=73\n",
    "VALIDATION_PERCENTAGE=25\n",
    "TEST_PERCENTAGE=2\n",
    "sFile='soteria_ss_rtw_health_based_risk_class.csv'\n",
    "trnFile='soteria_ss_rtw_health_based_risk_class_trn.csv'\n",
    "valFile='soteria_ss_rtw_health_based_risk_class_val.csv'\n",
    "tstFile='soteria_ss_rtw_health_based_risk_class_tst.csv'\n",
    "cListFile='ss_rtw_profile_health_based_risk_class_clist.txt'\n",
    "c=['encoded_risk_category', 'temperature', 'spo2', 'travel_history', 'positive_contact', 'symptoms_none', 'dry_cough', 'shortness_of_breath', 'chest_pain_or_pressure', 'confusion_or_problems_thinking', 'bluish_lips_or_face', 'sore_throat', 'fatigue', 'aches_and_pain', 'loss_of_appetite_or_smell', 'headache', 'stuffy_or_runny_nose', 'vomiting', 'diarrhea', 'sneezing', 'overall_health_status']\n",
    "dfAll=pd.read_csv(sFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW=0\n",
    "MEDIUM=1\n",
    "HIGH=2\n",
    "labels=[LOW, MEDIUM, HIGH]\n",
    "risk_categories=['0 - Low', '1 - Medium', '2 - High']\n",
    "lEnc=preprocessing.LabelEncoder()\n",
    "lEnc.fit(risk_categories)\n",
    "lEnc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform a quick check to see...\n",
    "* how many observations have been read and how many features each of those observations have\n",
    "* the break up of the number of observations under each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta=dfAll['risk_category'].value_counts()\n",
    "print('Total Rows in dataframe dfAll: {:,}\\nTotal Columns in dataframe dfAll: {:,}\\n'.format(dfAll.shape[0], dfAll.shape[1]))\n",
    "print('Observation composition as read...\\nLow risk: {:,}\\nMedium risk: {:,}\\nHigh risk: {:,}'.format (ta[0], ta[1], ta[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll['encoded_risk_category']=lEnc.transform(dfAll['risk_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates... and if present, remove the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Before checking for duplicates...\\nTotal Rows: {:,}\\nTotal Columns: {:,}\\n\\nDuplicates: {}\\n'.format(dfAll.shape[0], dfAll.shape[1], dfAll.duplicated().any()))\n",
    "dfFull=dfAll.drop_duplicates(keep='first')\n",
    "print ('After checking for duplicates...\\nTotal Rows: {:,}\\nTotal Columns: {:,}'.format(dfFull.shape[0], dfFull.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=dfFull['risk_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(sdf, TRAIN_PERCENTAGE, VALIDATION_PERCENTAGE, TEST_PERCENTAGE):\n",
    "    trn_set, v1=train_test_split(sdf, test_size=(100-TRAIN_PERCENTAGE)/100, stratify=sdf['encoded_risk_category'])\n",
    "    val_set, tst_set=train_test_split(v1, test_size=(TEST_PERCENTAGE/(VALIDATION_PERCENTAGE+TEST_PERCENTAGE)), stratify=v1['encoded_risk_category'])\n",
    "    return (trn_set, val_set, tst_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training, validation, and test set as per the split ratio...and review the observations are split accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set, val_set, tst_set=split_data(dfFull, TRAIN_PERCENTAGE, VALIDATION_PERCENTAGE, TEST_PERCENTAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review how the spread of the data is...\n",
    "* The total number of observations\n",
    "* The number of observations in the training, validation, and test sets\n",
    "* The overall composition of Low, Medium, and High risk observations\n",
    "* The training set composition of Low, Medium, and High risk observations\n",
    "* The validation set composition of Low, Medium, and High risk observations\n",
    "* The test set composition of Low, Medium, and High risk observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Total observations: {:,}'.format(dfFull.shape[0]))\n",
    "print ('Total observations in train set: {:,}'.format(trn_set.shape[0]))\n",
    "print ('Total observations in validation set: {:,}'.format(val_set.shape[0]))\n",
    "print ('Total observations in test set: {:,}\\n'.format(tst_set.shape[0]))\n",
    "trnc=trn_set['risk_category'].value_counts()\n",
    "valc=val_set['risk_category'].value_counts()\n",
    "tstc=tst_set['risk_category'].value_counts()\n",
    "print('Overall observation composition:\\nLow risk: {:,}\\nMedium rism: {:,}\\nHigh risk: {:,}\\n'.format (tf[0], tf[1], tf[2]))\n",
    "print('Training set composition:\\nLow risk: {:,}\\nMedium risk: {:,}\\nHigh risk: {:,}\\n'.format (trnc[0], trnc[1], trnc[2]))\n",
    "print('Validation set composition:\\nLow risk: {:,}\\nMedium risk: {:,}\\nHigh risk: {:,}\\n'.format (valc[0], valc[1], valc[2]))\n",
    "print('Test set composition:\\nLow risk: {:,}\\nMedium risk: {:,}\\nHigh risk: {:,}'.format (tstc[0], tstc[1], tstc[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the training, validation, and test set files and upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set[:].to_csv(trnFile, index=False, header=False, columns=c)\n",
    "val_set[:].to_csv(valFile, index=False, header=False, columns=c)\n",
    "tst_set[:].to_csv(tstFile, index=False, header=False, columns=c)\n",
    "with open(cListFile, 'w') as f:\n",
    "    f.write(','.join(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/'+trnFile)).upload_file(trnFile)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/'+valFile)).upload_file(valFile)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/'+tstFile)).upload_file(tstFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the XGBoost container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an instance of the sagemaker.estimator.Estimator class and specify the necessary parameters where,\n",
    "* role is the IAM role that Amazon SageMaker can assume to perform tasks on our behalf\n",
    "* train_instance_count is the number of ML compute instances to use for model training... for our purpose, we will use single training instance\n",
    "* train_instance_type is the type of ML compute instances to use for model training... for our purpose, we will use ml.ml.xlarge instance type\n",
    "\n",
    "#### Set the hyperparameters as needed and also tune some of the hyperparameters as needed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "classifier.set_hyperparameters(num_class=3,\n",
    "                        num_round=15000,\n",
    "                        objective='multi:softmax',\n",
    "                        early_stopping_rounds=10\n",
    "                       )\n",
    "\n",
    "hyperparameter_ranges = {'eta': ContinuousParameter(0, 1),\n",
    "                         'alpha': ContinuousParameter(0,2),\n",
    "                        'min_child_weight': ContinuousParameter(1, 10),\n",
    "                        'max_depth': IntegerParameter(1, 6)}\n",
    "\n",
    "tuner = HyperparameterTuner(classifier,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            objective_type='Minimize',\n",
    "                            base_tuning_job_name='XGB-HT-RPE',\n",
    "                            max_jobs=20,\n",
    "                            max_parallel_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the train and validation channels and start the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')\n",
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the progress of the job..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In our case, the <a id=\"reference_to_tuning_job\">tuning job name</a> is _XGB-HT-RPE-200712-1419_\n",
    "Make a note of the tuning job when you execute your tuning job (you will need this for a [later step](#section_tuning_job)) as it would be different and wait till all training jobs complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_result = smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)\n",
    "\n",
    "status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "if status != 'Completed':\n",
    "    print('Reminder: the tuning job has not been completed.')\n",
    "    \n",
    "job_count = tuning_job_result['TrainingJobStatusCounters']['Completed']\n",
    "print(\"%d training jobs have completed\" % job_count)\n",
    "    \n",
    "is_minimize = (tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['Type'] != 'Maximize')\n",
    "objective_name = tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['MetricName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkout the details of the best model that has been found so far..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning_job_result.get('BestTrainingJob',None):\n",
    "    print(\"Best model found so far:\")\n",
    "    pprint(tuning_job_result['BestTrainingJob'])\n",
    "else:\n",
    "    print(\"No training jobs have reported results yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "\n",
    "full_df = tuner.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df['FinalObjectiveValue'] > -float('inf')]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values('FinalObjectiveValue', ascending=is_minimize)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\":min(df['FinalObjectiveValue']),\"highest\": max(df['FinalObjectiveValue'])})\n",
    "        pd.set_option('display.max_colwidth', -1)  # Don't truncate TrainingJobName        \n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait till the training job completes...once complete, we should have the best performing model that we could deploy...\n",
    "* Let's get the best training job from the list of training jobs that were completed for the given tuning job and deploy the same\n",
    "  - As indicated earlier, in our case, the _tuning job name_ is _XGB-HT-RPE-200712-1419_\n",
    "  - Set the value for HP_TUNING_JOB_NAME below with the name of your <a id=\"section_tuning_job\">tuning job</a> that you noted in the [earlier step](#reference_to_tuning_job)\n",
    "* In our case, the _best training job_ was found to be _XGB-HT-RPE-200712-1419-016-33cf1420_\n",
    "* Make a note of the best training job in your case\n",
    "* Checkout the details of the best training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "HP_TUNING_JOB_NAME = 'XGB-HT-RPE-200712-1419'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuningJobStatus=sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=HP_TUNING_JOB_NAME)['HyperParameterTuningJobStatus']\n",
    "bestTrainingJobName=sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=HP_TUNING_JOB_NAME)['BestTrainingJob']['TrainingJobName']\n",
    "tunedhps=sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=HP_TUNING_JOB_NAME)['BestTrainingJob']['TunedHyperParameters']\n",
    "totalTrainingJobs=sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=HP_TUNING_JOB_NAME)['HyperParameterTuningJobConfig']['ResourceLimits']['MaxNumberOfTrainingJobs']\n",
    "print ('Tuning job name: {}\\nTuning job status: {}\\n\\nTotal jobs run: {}\\nBest training job: {}\\n\\nTuned hyperparameters for best job:'.format (HP_TUNING_JOB_NAME, tuningJobStatus, totalTrainingJobs, bestTrainingJobName))\n",
    "for hp in tunedhps:\n",
    "    print(' - {}: {:}'.format(hp, tunedhps[hp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestjobdetails=sm.describe_training_job(TrainingJobName=bestTrainingJobName)\n",
    "trainingImage=bestjobdetails['AlgorithmSpecification']['TrainingImage']\n",
    "modelPath=bestjobdetails['OutputDataConfig']['S3OutputPath']\n",
    "modelDataURL=bestjobdetails['ModelArtifacts']['S3ModelArtifacts']\n",
    "jobStatus=bestjobdetails['TrainingJobStatus']\n",
    "hps=bestjobdetails['HyperParameters']\n",
    "instanceType=bestjobdetails['ResourceConfig']['InstanceType']\n",
    "instanceCount=bestjobdetails['ResourceConfig']['InstanceCount']\n",
    "roleArn=bestjobdetails['RoleArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training job name: {}\\nTraining job status: {}\\nTraining image name: {}\\nModel path: {}\\nModel data URL: {}\\nHyperparameters:'.format(bestTrainingJobName, jobStatus, trainingImage, modelPath, modelDataURL))\n",
    "for hp in hps:\n",
    "    print('- {}: {:}'.format(hp, hps[hp]))\n",
    "print('Instance type: {}\\nInstance count: {}'.format(instanceType, instanceCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a deployable model by identifying the location of model artifacts and the Docker image that contains the inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = bestTrainingJobName + '-model'\n",
    "\n",
    "primary_container = {\n",
    "    'Image': trainingImage,\n",
    "    'ModelDataUrl': modelDataURL\n",
    "}\n",
    "\n",
    "createModelResponse = sm.create_model(\n",
    "    ModelName=modelName,\n",
    "    ExecutionRoleArn=roleArn,\n",
    "    PrimaryContainer=primary_container)\n",
    "\n",
    "print('Model name: {}\\nModel data: {}\\nModel Arn: {}'.format(modelName, modelDataURL, createModelResponse['ModelArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Amazon SageMaker endpoint configuration by specifying the ML compute instances that you want to deploy your model to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpointConfigName = bestTrainingJobName + '-epc'\n",
    "createEndpointConfigResponse = sm.create_endpoint_config(EndpointConfigName = endpointConfigName,\n",
    "                                                            ProductionVariants=[{'InstanceType':'ml.m4.xlarge',\n",
    "                                                                                 'InitialVariantWeight':1,\n",
    "                                                                                 'InitialInstanceCount':1,\n",
    "                                                                                 'ModelName':modelName,\n",
    "                                                                                 'VariantName':'AllTraffic'}])\n",
    "print('Endpoint config name: {}\\nEndpoint Config Arn: {}'.format(endpointConfigName, createEndpointConfigResponse['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model endpoint... it would take a few minutes... so, wait...\n",
    "* you should see a _status_ of ___Creating___ while the endpoint is being created\n",
    "* once the endpoint creation process is complete, you should see the _status_ as ___InService___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "endpointName = bestTrainingJobName + '-ep'\n",
    "\n",
    "createEndpointResponse = sm.create_endpoint(EndpointName=endpointName,\n",
    "                                            EndpointConfigName=endpointConfigName)\n",
    "print('Endpoint name: {}\\nEndpoint Arn: {}'.format(endpointName, createEndpointResponse['EndpointArn']))\n",
    "\n",
    "response = sm.describe_endpoint(EndpointName=endpointName)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    response = sm.describe_endpoint(EndpointName=endpointName)\n",
    "    status = response['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + response['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The status of ___InService___ from the above step indicates that the model endpoint has been successfully deployed for consumption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
